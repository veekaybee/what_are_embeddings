<!doctype html>
<html lang="en" class="h-100">

<head>
    <title>What are embeddings?</title>
    <meta name="description" content="A deep-dive into machine learning embeddings. ">

    <!-- Google / Search Engine Tags -->
    <meta itemprop="name" content="machine learning, embeddings, deep learning, vector search">
    <meta itemprop="description" content="A deep-dive into machine learning embeddings. ">
    <meta itemprop="image"
        content="https://raw.githubusercontent.com/veekaybee/what_are_embeddings/site/docs/assets/kandinsky.png">

    <!-- Facebook Meta Tags -->
    <meta property="og:url" content="http://vickiboykis.com/what_are_embeddings/index.html">
    <meta property="og:type" content="website">
    <meta property="og:title" content="What are embeddings?">
    <meta property="og:description" content="A deep-dive into machine learning embeddings. ">
    <meta property="og:image"
        content="https://raw.githubusercontent.com/veekaybee/what_are_embeddings/site/docs/assets/kandinsky.png">

    <!-- Twitter Meta Tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="What are embeddings?">
    <meta name="twitter:description" content="A deep-dive into machine learning embeddings. ">
    <meta name="twitter:image"
        content="https://raw.githubusercontent.com/veekaybee/what_are_embeddings/site/docs/assets/kandinsky.png">

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link href="assets/dist/css/bootstrap.min.css" rel="stylesheet">

    <style>
        .bd-placeholder-img {
            font-size: 1.125rem;
            text-anchor: middle;
            -webkit-user-select: none;
            -moz-user-select: none;
            user-select: none;
        }

        @media (min-width: 768px) {
            .bd-placeholder-img-lg {
                font-size: 3.5rem;
            }
        }

        .b-example-divider {
            height: 3rem;
            background-color: rgba(0, 0, 0, .1);
            border: solid rgba(0, 0, 0, .15);
            border-width: 1px 0;
            box-shadow: inset 0 .5em 1.5em rgba(0, 0, 0, .1), inset 0 .125em .5em rgba(0, 0, 0, .15);
        }

        .b-example-vr {
            flex-shrink: 0;
            width: 1.5rem;
            height: 100vh;
        }

        .bi {
            vertical-align: -.125em;
            fill: rgb(221, 131, 132);

        }

        .nav-scroller {
            position: relative;
            z-index: 2;
            height: 2.75rem;
            overflow-y: hidden;
        }

        .nav-scroller .nav {
            display: flex;
            flex-wrap: nowrap;
            padding-bottom: 1rem;
            margin-top: -1px;
            overflow-x: auto;
            text-align: center;
            white-space: nowrap;
            -webkit-overflow-scrolling: touch;
        }

        .blue-div {
            background-color: #a8cbfe;
            ;
        }

        .indigo-text {
            color: #228c3a !important;
        }

        .left-align {
            text-align: left;
        }

        .custom-padding {
            padding-top: 20px;
        }

        img {
            width: auto;
            max-width: 100%;
            height: auto;
        }
    </style>


    <!-- Custom styles for this template -->
    <link href="css/cover.css" rel="stylesheet">
</head>

<body class="text-center">

    <div class="cover-container d-flex w-100 h-100 p-3 mx-auto flex-column">
        <header class="mb-auto">
            <div>
                <nav class="nav nav-masthead justify-content-center text-primary float-md-end">
                    <a class="nav-link fw-bold py-1 px-0 active  text-primary" aria-current="page"
                        href="https://www.vickiboykis.com/what_are_embeddings">Home</a>
                    <a class="nav-link fw-bold py-1 px-0  text-primary"
                        href="https://github.com/veekaybee/what_are_embeddings">GitHub</a>
                </nav>
            </div>
        </header>

        <main class="px-3">
            <div class="container my-5">
                <div class="p-5 text-center blue-div rounded-3">
                    <p><img src="assets/kandinsky.png" width="150" height="150"></p>
                    <h1 class="text-body-emphasis text-primary indigo-text">What are embeddings?</h1>

                    <p class="lead">
                    <div class="row">
                        <div class="col-md-12">
                            <a href="https://raw.githubusercontent.com/veekaybee/what_are_embeddings/main/embeddings.pdf"
                                class="btn btn-lg btn-success mb-2 mb-md-0">Get PDF</a>
                            <a href="https://github.com/veekaybee/what_are_embeddings" button type="button"
                                class="btn btn-lg btn-success">Get Code</a>
                        </div>
                    </div>
                    </p>

                    <ul class="nav nav-tabs gap-2 justify-content-center">
                        <li class="nav-item">
                            <a class="nav-link" href="index.html">Why</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link " href="about.html">Who</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link active" aria-current="page" href="next.html">Next</a>
                        </li>

                    </ul>
                    <div class="row custom-padding">
                        <div class="text-left gap-3">
                            <p class="left-align">If you've read the paper and have more questions than answers or
                                are dying to read more about embeddings, you can read the <a
                                    href="https://github.com/veekaybee/what_are_embeddings/blob/main/embeddings.bib">bibliography</a>.
                                I've also picked out a curated shorter reading list to get you started.
                                If you're looking for how to learn machine learning, you can <a
                                    href="https://vickiboykis.com/2022/11/10/how-i-learn-machine-learning/">check out my
                                    post on how I do it here</a>. Also check out my <a
                                    href="http://vickiboykis.com/ml-garden/">ML notes</a>.
                            <h2> Embeddings
                            </h2>
                            <ul class="list-group">
                                <li class="list-group-item"><a href="https://arxiv.org/abs/1901.09069">Word Embeddings -
                                        A Survey</a></li>
                                <li class="list-group-item"><a
                                        href="https://www.pinecone.io/learn/dense-vector-embeddings-nlp/">Dense
                                        Vector Embeddings</a></li>
                                <li class="list-group-item"><a
                                        href="https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture/">Google's
                                        Short Embeddings Course</a></li>
                                <li class="list-group-item"><a
                                        href="https://cla2019.github.io/embedmatrix.pdf">Embeddings learned by matrix
                                        factorization</a></li>
                            </ul>
                            </p>
                            <h2> Recommender Systems
                            </h2>
                            <ul class=" list-group">
                                <li class="list-group-item"><a href="https://arxiv.org/abs/2302.02579">Recommender
                                        Systems - A Primer</a> - This covers a comprehensive survey of recommender
                                    systems from two of the most senior people in the field. </li>
                                <li class="list-group-item"><a
                                        href="https://www.manning.com/books/practical-recommender-systems">Practical
                                        Recommender Systems</a> - Great Walkthrough Book with Code</li>
                                <li class="list-group-item"><a href="https://nickseaver.net/">Computing Taste:
                                        Algorithms and the Makers of Music Recommendation</a> - Excellent book surveying
                                    music recommendations and the history of the field</li>
                                <li class="list-group-item"><a href="https://arxiv.org/pdf/1707.07435.pdf">Survey Paper
                                        on Deep
                                        Learning in Recommendations</a></li>
                                <li class="list-group-item"><a
                                        href="https://md.ekstrandom.net/blog/2015/10/search-and-recsys">The
                                        difference between search and recommendation</a></li>
                                <li class="list-group-item"><a
                                        href="https://eugeneyan.com/writing/system-design-for-discovery/">System Design
                                        for recommendation and search</a></li>
                            </ul>
                            </p>
                            <h2> Vector Databases
                            </h2>
                            <ul class=" list-group">
                                <li class="list-group-item"><a href="https://ann-benchmarks.com/">ANN Benchmarks</a> -
                                    Website with benchmark algos on approximate nearest neighbors search
                                </li>
                                <li class="list-group-item"><a
                                        href="https://www.pinecone.io/learn/faiss-tutorial/">Faiss similarity search</a>
                                </li>

                            </ul>
                            <p></p>
                            <h2> LLMs
                            </h2>
                            <ul class=" list-group">
                                <li class="list-group-item"><a href="https://sebastianraschka.com/blog/2023/llm-reading-list.html">Understanding
                                        Large Language Models -- A Transformative Reading List</a> - Sebastian's whole
                                    site is very worth reading, start with this survey of LLM posts and literature</li>
                                <li class="list-group-item"><a href="https://arxiv.org/abs/1510.00726">A
                                        Primer on Neural Network Models for Natural Language Processing</a> - Good idea
                                    to read everything Yoav has written but this is a great start</li>
                                <li class="list-group-item"><a href="https://github.com/ray-project/llm-numbers">Figures
                                        Everyone Should Know</a></li>
                                <li class="list-group-item"><a
                                        href="https://e2eml.school/transformers.html">Transformers from Scratch</a>
                                    - This is the one I come back to every time.
                                </li>
                                <li class="list-group-item"><a
                                        href="https://jalammar.github.io/illustrated-word2vec/">Illustrated
                                        Word2Vec</a>
                                    - Jay's site is extremely good, this one is particularly good for Word2Vec
                                </li>
                                <li class="list-group-item"><a
                                        href="https://lilianweng.github.io/posts/2018-06-24-attention/">Attention?
                                        Attention!</a>
                                    - Deep dive into the attention mechanism.
                                </li>
                                <li class="list-group-item"><a
                                        href="https://www.ruder.io/a-review-of-the-recent-history-of-nlp/">A History of
                                        NLP</a>
                                    - Great summary of the field over the last 20 or so years.
                                </li>
                                <li class="list-group-item"><a href="https://d2l.ai/index.html">Dive into Deep Learning
                                        Course</a>
                                </li>

                            </ul>
                            </p>
                            <h2> Machine Learning Engineering
                            </h2>
                            <ul class=" list-group">
                                <li class="list-group-item"><a
                                        href="https://www.oreilly.com/library/view/machine-learning-design/9781098115777/">Machine
                                        Learning
                                        Design Patterns</a> - Fantastic book covering a variety of engineering
                                    considerations, including embeddings</li>
                                <li class="list-group-item"><a
                                        href="https://www.brendangregg.com/blog/2020-07-15/systems-performance-2nd-edition.html">Systems
                                        Performance - From the guy who made flame charts, an amazing resource on
                                        engineering best practices</a></li>
                                <li class="list-group-item"><a
                                        href="https://www.peterbaumgartner.com/blog/notes-on-nlp-projects/">Notes
                                        on NLP Projects</a> - Criteria for starting a new one</li>
                                <li class="list-group-item"><a href="https://pages.cs.wisc.edu/~remzi/OSTEP/">Operating
                                        Systems: Three Easy Pieces</a> - A classic for diving deep into the stack</li>
                                <li class="list-group-item"><a href="https://hardwarelottery.github.io/">The
                                        Hardware Lottery</a> - Understanding why we develop neural nets the way we do,
                                    an extension of <a
                                        href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">The Bitter
                                        Lesson</a>
                                <li class="list-group-item"><a href="<li class=" list-group-item"><a
                                            href="https://huggingface.co/docs/transformers/perf_train_gpu_many">Efficiently
                                            training on multiple GPUs</a>
                                </li>

                            </ul>
                            </p>


                        </div>


                    </div>
                </div>
            </div>
        </main>
        <hr>
    </div>


    <footer class=" mt-auto text-black-50">
        <p>A thing from <a href="https://vickiboykis.com/">Vicki Boykis</a>.</p>
    </footer>
    </div>

</body>



</html>